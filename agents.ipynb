{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\codehub\\Rag Projects\\project 2\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = str(os.getenv(\"HUGGINGFACE_API_KEY\"))\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = str(os.getenv(\"LANGCHAIN_API_KEY\"))\n",
    "os.environ[\"GROQ_API_KEY\"] = str(os.getenv(\"Groq_Api_key\"))\n",
    "os.environ[\"TAVILY_API_KEY\"] = str(os.getenv(\"tavily_api_key\"))\n",
    "# Load document_loaders\n",
    "\n",
    "loader1 = WebBaseLoader(\"https://python.langchain.com/docs/tutorials/graph/\")\n",
    "loader2 = WebBaseLoader(\"https://python.langchain.com/docs/tutorials/agents/\")\n",
    "docs1 = loader1.load_and_split()\n",
    "docs2 = loader2.load_and_split()\n",
    "\n",
    "docs = [docs1 , docs2]\n",
    "\n",
    "# Split documents\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "splits = splitter.split_documents( docs2)\n",
    "\n",
    "#Embeddings\n",
    "\n",
    "embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# VectorStore\n",
    "\n",
    "index = FAISS.from_documents(splits[:100], embed)\n",
    "\n",
    "# retrieve\n",
    "\n",
    "retriever = index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL 5300 A&I\\AppData\\Local\\Temp\\ipykernel_15780\\2895562204.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriever.get_relevant_documents(\"what is agent workflow?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"Agents are a complex topic with lots to learn!\\nFor more information on Agents, please check out the LangGraph documentation. This has it's own set of concepts, tutorials, and how-to guides.Edit this pageWas this page helpful?PreviousBuild an Extraction ChainNextTaggingEnd-to-end agentSetupJupyter NotebookInstallationLangSmithTavilyDefine toolsUsing Language ModelsCreate the agentRun the agentStreaming MessagesStreaming tokensAdding in memoryConclusionCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2024 LangChain, Inc.\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Build an Agent | ü¶úÔ∏èüîó LangChain'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='In order to see exactly what is happening under the hood (and to make sure it\\'s not calling a tool) we can take a look at the LangSmith trace\\nLet\\'s now try it out on an example where it should be invoking the tool\\nresponse = agent_executor.invoke(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]})response[\"messages\"]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | ü¶úÔ∏èüîó LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='{\\'agent\\': {\\'messages\\': [AIMessage(content=\"I\\'m afraid I don\\'t actually know your name. As an AI assistant without personal information about you, I don\\'t have a specific name associated with our conversation.\", response_metadata={\\'id\\': \\'msg_01NoaXNNYZKSoBncPcLkdcbo\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 267, \\'output_tokens\\': 36}}, id=\\'run-c9f7df3d-525a-4d8f-bbcf-a5b4a5d2e4b0-0\\', usage_metadata={\\'input_tokens\\': 267, \\'output_tokens\\': 36, \\'total_tokens\\': 303})]}}----\\nConclusion\\u200b\\nThat\\'s a wrap! In this quick start we covered how to create a simple agent.\\nWe\\'ve then shown how to stream back a response - not only with the intermediate steps, but also tokens!\\nWe\\'ve also added in memory so you can have a conversation with them.\\nAgents are a complex topic with lots to learn!')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what is agent workflow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(retriever , \"langchain_retriver_tool\" ,\n",
    "                                       \"You are a retriever tool that retrieve relevant documents from the database\")\n",
    "\n",
    "tavily = TavilySearchResults(max_results=1)\n",
    " \n",
    "tools = [retriever_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#llm\n",
    "llm2 = ChatGroq(model = \"llama-3.1-70b-versatile\")\n",
    "\n",
    "#prompt\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is langchain?',\n",
       " 'output': 'LangChain is a system that supports the use of multiple language models interchangeably and allows for the creation of agents that can interact with various tools, such as a search engine. It provides a way to build conversational AI models that can perform tasks, make decisions, and take actions based on the input they receive. LangChain also includes tools for inspecting and understanding the inner workings of these models, making it easier to debug and improve their performance.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent = create_tool_calling_agent(llm2, tools, prompt)\n",
    "agent_executer = AgentExecutor(agent=agent,tools=tools)\n",
    "\n",
    "agent_executer.invoke({'input':'what is langchain?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict , Annotated , List , Union\n",
    "from langchain_core.agents import AgentAction , AgentFinish \n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # input string\n",
    "    input:str\n",
    "    # list of previus messeges in the conversation\n",
    "    chat_history: list[BaseMessage]\n",
    "    # outcome of given call to the agent\n",
    "    # need 'none' as valid type , this is what this is start as\n",
    "    agent_outcome: Union[AgentAction , AgentFinish , None]\n",
    "    # list of action and intermediate steps \n",
    "    # Here we annotate with 'operater.add' to indicate that operater  \n",
    "    # to this state should be added to the existing state (not overwritting it)\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str ]] , operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL 5300 A&I\\AppData\\Local\\Temp\\ipykernel_15780\\3894753885.py:3: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  tool_executer = ToolExecutor(tools)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "\n",
    "tool_executer = ToolExecutor(tools)\n",
    "\n",
    "#run agent\n",
    "def run_agent(data):\n",
    "    agent_outcome = agent.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "# define function to execute tools\n",
    "def execute_tools(data):\n",
    "    # get the most recent agent outcome - this is key added to the agent above\n",
    "    agent_action = data[\"agent_outcome\"]\n",
    "    output = tool_executer.invoke(agent_action)\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "def should_continue(data):\n",
    "    if isinstance(data[\"agent_outcome\"],AgentFinish):\n",
    "        return \"End\"\n",
    "    else:\n",
    "        return \"Continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END , StateGraph\n",
    "\n",
    "# langgraph workflows\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "#define the noes we will cylcle between\n",
    "workflow.add_node(\"agent\" , run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# define the edges between the nodes\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\" ,\n",
    "    should_continue ,\n",
    "    {\n",
    "        \"Continue\": \"action\",\n",
    "        \"End\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"action\" ,\"agent\")\n",
    "\n",
    "# compile the workflow\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pregel.invoke of <langgraph.graph.state.CompiledStateGraph object at 0x0000028C141811F0>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentFinish(return_values={'output': \"LangGraph is not a widely recognized term. However, based on the context of the conversation, it seems like LangGraph might be related to LangChain, which is an open-source platform for building applications that involve large language models.\\n\\nLangChain provides a set of tools and APIs for working with language models, including support for multiple AI models, model serving, and integration with databases and other data sources. The platform is designed to make it easier to build and deploy applications that use large language models, such as chatbots, language translation systems, and text summarization tools.\\n\\nIf you have any specific questions about LangChain or its features, I'd be happy to try to help.\"}, log=\"LangGraph is not a widely recognized term. However, based on the context of the conversation, it seems like LangGraph might be related to LangChain, which is an open-source platform for building applications that involve large language models.\\n\\nLangChain provides a set of tools and APIs for working with language models, including support for multiple AI models, model serving, and integration with databases and other data sources. The platform is designed to make it easier to build and deploy applications that use large language models, such as chatbots, language translation systems, and text summarization tools.\\n\\nIf you have any specific questions about LangChain or its features, I'd be happy to try to help.\")}\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "input = {\"input\":\"what is langraph\", \"chat_history\":[]}\n",
    "\n",
    "# run the workflow\n",
    "for s in app.stream(input):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"--------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
